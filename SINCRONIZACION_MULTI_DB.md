# ğŸ”„ SincronizaciÃ³n Multi-Base de Datos

## Arquitectura General

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PostgreSQL (ACID)     â”‚
                    â”‚   Source of Truth       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  COMMIT EXITOSO       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                   â”‚                   â”‚
            â–¼                   â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Cassandra   â”‚   â”‚    MongoDB    â”‚  â”‚    Neo4j     â”‚
    â”‚  (Analytics)  â”‚   â”‚ (Agregaciones)â”‚  â”‚   (Grafos)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         ASYNC               ASYNC              ASYNC
    (No bloquea)        (No bloquea)       (No bloquea)

    âŒ Si falla: Se loggea, pero NO revierte PostgreSQL
```

---

## ğŸ“Š PatrÃ³n 1: PostgreSQL â†’ Cassandra

### **Objetivo**: Desnormalizar datos para queries analÃ­ticas rÃ¡pidas

### **ImplementaciÃ³n**: Write-Behind Pattern

```python
# services/reservations.py - create_reservation()

async def create_reservation(...):
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # FASE 1: ACID TRANSACTION EN POSTGRESQL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    pool = await get_client()
    async with pool.acquire() as conn:
        async with conn.transaction():  # âœ… TransacciÃ³n ACID
            # Validar disponibilidad
            is_available = await self._check_availability(...)

            # Calcular precio
            total_price = await self._calculate_total_price(...)

            # Insertar reserva
            query = """
                INSERT INTO reserva (
                    propiedad_id, huesped_id, fecha_check_in,
                    fecha_check_out, monto_final, estado_reserva_id
                )
                VALUES ($1, $2, $3, $4, $5, $6)
                RETURNING id
            """
            result = await conn.fetchrow(query, ...)
            reserva_id = result['id']

            # Marcar fechas como no disponibles
            await self._mark_dates_unavailable(...)

            # âœ… COMMIT implÃ­cito al salir del bloque
            logger.info(f"âœ… Reserva {reserva_id} creada en PostgreSQL")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # FASE 2: SINCRONIZACIÃ“N ASYNC (FUERA DE TRANSACCIÃ“N)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # âš¡ Sincronizar a Cassandra (no bloquea)
    await self._sync_reservation_to_cassandra(
        reserva_id=str(reserva_id),
        event_type="CREATED",
        propiedad_id=propiedad_id,
        huesped_id=str(huesped_id),
        check_in=check_in,
        check_out=check_out,
        monto_total=total_price
    )
    # âŒ Si falla: Solo se loggea, NO se revierte PostgreSQL

    # âš¡ Invalidar cache Redis
    from services.search import invalidate_search_cache_for_city
    await invalidate_search_cache_for_city(ciudad_id)

    # âš¡ Actualizar Neo4j (comunidades y usuarios recurrentes)
    await self._update_neo4j_recurrent_booking(huesped_id, city_name)

    return {"success": True, "reservation": {...}}
```

### **Manejo de Errores en Cassandra**

```python
async def _sync_reservation_to_cassandra(...):
    try:
        repo = await self.cassandra_repo
        if not repo:
            logger.warning("Cassandra no disponible, saltando sincronizaciÃ³n")
            return  # âœ… ContinÃºa sin fallar

        # Sincronizar datos
        await repo.sync_reservation_creation(...)
        logger.info("âœ… Sincronizado con Cassandra")

    except Exception as e:
        # âŒ Error en Cassandra NO revierte PostgreSQL
        logger.error(f"âŒ Error sincronizando Cassandra: {e}")
        logger.info(f"ğŸ“ Evento registrado para reintento futuro")
        # Sistema continÃºa funcionando
```

### **GarantÃ­as**

- âœ… **PostgreSQL**: ACID - Datos consistentes siempre
- âš ï¸  **Cassandra**: Eventual Consistency - Puede tener latencia
- ğŸ”„ **ReconciliaciÃ³n**: Posible implementar job de reconciliaciÃ³n periÃ³dica

---

## ğŸ“ˆ PatrÃ³n 2: PostgreSQL â†’ MongoDB

### **Objetivo**: Mantener agregaciones y estadÃ­sticas precalculadas

### **ImplementaciÃ³n**: Event-Driven Updates

```python
# services/reviews.py - create_review()

async def create_review(reserva_id, huesped_id, anfitrion_id, puntaje, comentario):
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 1: VALIDAR EN POSTGRESQL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    validation = await self._validate_reservation(...)
    if not validation['valid']:
        return {"success": False, "error": "..."}

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 2: INSERTAR EN POSTGRESQL (SOURCE OF TRUTH)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    review_id = await self._insert_review_postgres(...)
    logger.info(f"âœ… ReseÃ±a {review_id} insertada en PostgreSQL")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 3: ACTUALIZAR ESTADÃSTICAS EN MONGODB
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    mongo_result = await self._update_mongo_stats(anfitrion_id, puntaje)
    if not mongo_result['success']:
        logger.warning(f"âš ï¸  MongoDB fallÃ³: {mongo_result['error']}")
        # âœ… ReseÃ±a existe en PostgreSQL, continÃºa el flujo

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 4: ENRIQUECER GRAFO EN NEO4J
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    neo4j_result = await self._update_neo4j_review(...)
    if not neo4j_result['success']:
        logger.warning(f"âš ï¸  Neo4j fallÃ³: {neo4j_result['error']}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 5: RETORNAR RESULTADO PARCIAL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    return {
        "success": True,
        "review_id": review_id,
        "postgres_success": True,      # âœ… CrÃ­tico
        "mongo_success": mongo_result['success'],    # âš ï¸  Opcional
        "neo4j_success": neo4j_result['success'],    # âš ï¸  Opcional
        "message": "ReseÃ±a creada exitosamente"
    }
```

### **ActualizaciÃ³n de EstadÃ­sticas en MongoDB**

```python
async def _update_mongo_stats(anfitrion_id: int, puntaje: int):
    try:
        collection = get_collection("host_statistics")

        # Obtener estadÃ­sticas actuales
        current_stats = collection.find_one({"host_id": anfitrion_id})

        if current_stats:
            # Actualizar estadÃ­sticas existentes (agregaciones)
            total_reviews = current_stats.get('total_reviews', 0) + 1
            total_rating = current_stats.get('total_rating', 0) + puntaje
            avg_rating = total_rating / total_reviews

            collection.update_one(
                {"host_id": anfitrion_id},
                {
                    "$set": {
                        "total_reviews": total_reviews,
                        "avg_rating": round(avg_rating, 2),
                        "updated_at": datetime.utcnow()
                    },
                    "$push": {
                        "recent_ratings": {"rating": puntaje, "date": datetime.utcnow()}
                    }
                }
            )
        else:
            # Crear documento inicial
            collection.insert_one({
                "host_id": anfitrion_id,
                "total_reviews": 1,
                "avg_rating": puntaje,
                "recent_ratings": [{"rating": puntaje, "date": datetime.utcnow()}]
            })

        return {"success": True}

    except Exception as e:
        logger.error(f"Error en MongoDB: {e}")
        return {"success": False, "error": str(e)}
```

### **GarantÃ­as**

- âœ… **PostgreSQL**: Todas las reseÃ±as estÃ¡n guardadas
- âš ï¸  **MongoDB**: Puede tener estadÃ­sticas desactualizadas temporalmente
- ğŸ”„ **ReconciliaciÃ³n**: Job nocturno recalcula estadÃ­sticas desde PostgreSQL

---

## ğŸ•¸ï¸ PatrÃ³n 3: PostgreSQL â†’ Neo4j

### **Objetivo**: Mantener grafo de relaciones sociales

### **ImplementaciÃ³n**: Dual-Write Pattern

```python
# services/reservations.py - create_reservation()

# DespuÃ©s de crear reserva en PostgreSQL...

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ACTUALIZACIÃ“N 1: USUARIOS RECURRENTES (CU 9)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    await self._update_neo4j_recurrent_booking(huesped_id, city_name)
    # Crea/actualiza: (User)-[BOOKED_IN {count}]->(City)
except Exception as e:
    logger.error(f"âŒ Neo4j (recurrentes) fallÃ³: {e}")
    # Fallback al simulador
    result = neo4j_simulator.simulate_recurrent_booking_analysis(...)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ACTUALIZACIÃ“N 2: COMUNIDADES HOST-HUÃ‰SPED (CU 10)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    neo4j_result = await self.neo4j_service.create_host_guest_interaction(
        host_user_id=anfitrion_id,
        guest_user_id=huesped_id,
        reservation_id=reserva_id,
        reservation_date=check_in,
        property_id=propiedad_id
    )
    # Crea/actualiza: (Guest)-[INTERACCIONES {count, reservas[], propiedades[]}]->(Host)

    if neo4j_result.get('is_community'):
        logger.info(f"ğŸ˜ï¸ Â¡Nueva comunidad! {total_interactions} interacciones")

except Exception as e:
    logger.warning(f"âŒ Neo4j (comunidades) fallÃ³: {e}")
    # Fallback al simulador
    neo4j_simulator.simulate_user_interaction(...)
```

### **Query Neo4j - Usuarios Recurrentes**

```cypher
// Crear/actualizar relaciÃ³n User-City
MERGE (u:User {id: $user_id})
MERGE (c:City {name: $city_name})
MERGE (u)-[r:BOOKED_IN]->(c)
ON CREATE SET r.count = 1
ON MATCH SET r.count = r.count + 1
RETURN r.count as count
```

### **Query Neo4j - Comunidades Host-HuÃ©sped**

```cypher
// Crear/actualizar relaciÃ³n Guest-Host
MERGE (host:Usuario {user_id: $host_id})
MERGE (guest:Usuario {user_id: $guest_id})
MERGE (guest)-[rel:INTERACCIONES]->(host)
ON CREATE SET
    rel.count = 1,
    rel.reservas = [$reservation_id],
    rel.propiedades = [$property_id],
    rel.primera_interaccion = date($fecha),
    rel.created_at = datetime()
ON MATCH SET
    rel.count = rel.count + 1,
    rel.reservas = rel.reservas + $reservation_id,
    rel.propiedades = CASE
        WHEN $property_id IN rel.propiedades
        THEN rel.propiedades
        ELSE rel.propiedades + $property_id
    END,
    rel.ultima_interaccion = date($fecha)
RETURN
    rel.count as total_interacciones,
    size(rel.propiedades) as propiedades_distintas
```

### **GarantÃ­as**

- âœ… **PostgreSQL**: Reservas siempre almacenadas
- âš ï¸  **Neo4j**: Grafo puede tener relaciones faltantes
- ğŸ”„ **Fallback**: Simulador para demostraciÃ³n si Neo4j falla
- ğŸ”„ **ReconciliaciÃ³n**: Script de rebuild del grafo desde PostgreSQL

---

## ğŸ’¾ PatrÃ³n 4: PostgreSQL â†’ Redis

### **Objetivo**: Cache de lectura con invalidaciÃ³n inteligente

### **ImplementaciÃ³n**: Cache-Aside + Write-Invalidate

```python
# services/search.py

async def search_properties(ciudad, capacidad_minima=None, precio_maximo=None):
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 1: INTENTAR LEER DESDE CACHE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    cache_key = self._generate_cache_key(ciudad, capacidad_minima, precio_maximo)
    cached_data = await get_key(cache_key)

    if cached_data:
        logger.info(f"ğŸŸ¢ CACHE HIT: {cache_key}")
        result = json.loads(cached_data)
        result['cached'] = True
        return result

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 2: CACHE MISS - CONSULTAR POSTGRESQL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    logger.info(f"ğŸ”´ CACHE MISS: Consultando PostgreSQL")

    pool = await postgres.get_client()
    rows = await pool.fetch("""
        SELECT p.id, p.nombre, p.capacidad, AVG(pd.price_per_night) as precio
        FROM propiedad p
        JOIN ciudad c ON p.ciudad_id = c.id
        JOIN propiedad_servicio ps ON p.id = ps.propiedad_id
        WHERE c.nombre = $1
        AND p.capacidad >= $2
        ...
    """, ciudad, capacidad_minima)

    result = {
        "success": True,
        "properties": [dict(row) for row in rows],
        "count": len(rows),
        "cached": False
    }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 3: GUARDAR EN CACHE CON TTL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    await set_key(cache_key, json.dumps(result), expire=300)  # 5 minutos

    # Trackear clave para invalidaciÃ³n posterior
    tracking_key = f"search_keys:ciudad:{ciudad_id}"
    await add_to_set(tracking_key, cache_key)

    logger.info(f"ğŸ’¾ Guardado en cache: {cache_key} (TTL: 5 min)")

    return result
```

### **InvalidaciÃ³n del Cache**

```python
# services/reservations.py - create_reservation()

# DespuÃ©s de crear reserva en PostgreSQL...

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INVALIDAR CACHE DE BÃšSQUEDAS PARA LA CIUDAD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from services.search import invalidate_search_cache_for_city
    await invalidate_search_cache_for_city(propiedad['ciudad_id'])
    logger.info(f"ğŸ—‘ï¸  Cache invalidado para ciudad_id {propiedad['ciudad_id']}")
except Exception as cache_error:
    logger.warning(f"âš ï¸  Error invalidando cache: {cache_error}")
    # No fallar la reserva por esto


# services/search.py
async def invalidate_search_cache_for_city(ciudad_id: int):
    """Invalida todas las bÃºsquedas en cache para una ciudad."""
    tracking_key = f"search_keys:ciudad:{ciudad_id}"
    deleted_count = await delete_keys_in_set(tracking_key)
    logger.info(f"ğŸ—‘ï¸  {deleted_count} claves eliminadas del cache")
```

### **GarantÃ­as**

- âœ… **PostgreSQL**: Source of truth siempre actualizado
- âœ… **Redis**: Cache se invalida automÃ¡ticamente al crear/cancelar reservas
- âš¡ **Performance**: Primera bÃºsqueda lenta, subsiguientes < 1ms
- ğŸ• **TTL**: Cache expira a los 5 minutos automÃ¡ticamente

---

## ğŸ› ï¸ Estrategias de ReconciliaciÃ³n

### **1. Job Nocturno de ReconciliaciÃ³n**

```python
# jobs/reconciliation_job.py

async def reconcile_cassandra_reservations():
    """
    Job nocturno que compara PostgreSQL vs Cassandra
    y sincroniza diferencias.
    """
    # Obtener todas las reservas de PostgreSQL
    pg_reservations = await postgres.fetch("""
        SELECT id, propiedad_id, huesped_id, fecha_check_in, fecha_check_out
        FROM reserva
        WHERE created_at > NOW() - INTERVAL '7 days'
    """)

    # Para cada reserva, verificar si existe en Cassandra
    for reservation in pg_reservations:
        exists_in_cassandra = await check_cassandra_reservation(reservation.id)

        if not exists_in_cassandra:
            # Resincronizar
            await sync_reservation_to_cassandra(reservation)
            logger.info(f"ğŸ”„ Resincronizada reserva {reservation.id}")
```

### **2. Event Sourcing (Futuro)**

```python
# Para sistemas crÃ­ticos, guardar todos los eventos

# events/reservation_created.py
async def handle_reservation_created(event):
    """
    Evento: Reserva creada en PostgreSQL

    Subscriptores:
    - Cassandra Sync Handler
    - MongoDB Stats Handler
    - Neo4j Graph Handler
    - Redis Cache Invalidator
    """
    await asyncio.gather(
        sync_to_cassandra(event),
        update_mongo_stats(event),
        update_neo4j_graph(event),
        invalidate_redis_cache(event)
    )
```

### **3. Monitoring y Alertas**

```python
# Monitorear inconsistencias

async def check_sync_health():
    """Verifica que las bases estÃ©n sincronizadas."""

    # Contar reservas en cada DB
    pg_count = await postgres.fetchval("SELECT COUNT(*) FROM reserva")
    cassandra_count = await cassandra.count_reservations()

    diff = abs(pg_count - cassandra_count)

    if diff > 100:
        # Alerta: Diferencia > 100 registros
        logger.error(f"âš ï¸  INCONSISTENCIA: PG={pg_count}, Cassandra={cassandra_count}")
        send_alert("Bases desincronizadas")
```

---

## ğŸ“‹ Resumen de GarantÃ­as

| Base de Datos | Rol | Consistencia | Manejo de Fallo |
|---------------|-----|--------------|-----------------|
| **PostgreSQL** | Source of Truth | ACID (Strong) | âŒ Falla = Rollback completo |
| **Cassandra** | Analytics denormalized | Eventual | âš ï¸  Falla = Se loggea, continÃºa |
| **MongoDB** | Agregaciones | Eventual | âš ï¸  Falla = Se loggea, continÃºa |
| **Neo4j** | Grafos de relaciones | Eventual | âš ï¸  Falla = Fallback a simulador |
| **Redis** | Cache con TTL | Cache-Aside | âš ï¸  Falla = Sin cache, continÃºa |

---

## ğŸ¯ Decisiones de DiseÃ±o

### **Â¿Por quÃ© NO revertir PostgreSQL si falla NoSQL?**

1. **Disponibilidad > Consistencia**: Sistema sigue funcionando
2. **PostgreSQL es la verdad**: Podemos reconstruir NoSQL desde ahÃ­
3. **Fallos temporales**: Red puede fallar momentÃ¡neamente
4. **ReconciliaciÃ³n posterior**: Jobs nocturnos corrigen inconsistencias

### **Â¿CuÃ¡ndo SÃ revertir?**

Solo si falla una operaciÃ³n **crÃ­tica** en PostgreSQL:
- ValidaciÃ³n de disponibilidad
- CÃ¡lculo de precio
- InserciÃ³n de reserva
- Marcar fechas como no disponibles

### **Trade-offs**

âœ… **Ventajas**:
- Alta disponibilidad
- Performance (operaciones async)
- Escalabilidad independiente de cada DB

âš ï¸ **Desventajas**:
- Eventual consistency
- Posibles inconsistencias temporales
- Complejidad de reconciliaciÃ³n

---

## ğŸ” Debugging de SincronizaciÃ³n

### **Script de VerificaciÃ³n**

```bash
# Verificar que una reserva estÃ© sincronizada
python scripts/verify_sync.py --reservation-id 123

# Output:
âœ… PostgreSQL: Reserva 123 existe
âœ… Cassandra: Reserva 123 encontrada en 3 tablas
âš ï¸  MongoDB: Stats del host desactualizadas
âœ… Neo4j: RelaciÃ³n User-City actualizada
âœ… Redis: Cache invalidado correctamente
```

### **Logs Estructurados**

```python
logger.info("Reserva creada",
    reserva_id=reserva_id,
    postgres_success=True,
    cassandra_success=cassandra_ok,
    neo4j_success=neo4j_ok,
    redis_invalidated=cache_cleared
)
```

---

## ğŸ“š Referencias

- **CAP Theorem**: Elegimos Availability + Partition Tolerance
- **BASE**: Basically Available, Soft state, Eventual consistency
- **Write-Behind Pattern**: Cassandra sync
- **Cache-Aside Pattern**: Redis cache
- **Event Sourcing**: Futuro para audit trail completo
